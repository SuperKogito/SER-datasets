.. ser-datasets documentation master file, created by
   sphinx-quickstart on Thu Apr 21 01:17:30 2022.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

Datasets
========

Spoken Emotion Recognition Datasets: A collection of datasets for the purpose of emotion recognition/detection in speech.
The table is chronologically ordered and includes a description of the content of each dataset along with the emotions included.


.. csv-filter:: SER-Datasets
   :file: ser-datasets.csv
   :header-rows: 1
   :class: datatable


References
==========

- Swain, Monorama & Routray, Aurobinda & Kabisatpathy, Prithviraj, Databases, features and classifiers for speech emotion recognition: a review, International Journal of Speech Technology, `paper1 <https://www.researchgate.net/publication/322602563_Databases_features_and_classifiers_for_speech_emotion_recognition_a_review#pf19>`_
- Dimitrios Ververidis and Constantine Kotropoulos, A State of the Art Review on Emotional Speech Databases, Artificial Intelligence & Information Analysis Laboratory, Department of Informatics Aristotle, University of Thessaloniki, `paper2 <http://poseidon.csd.auth.gr/papers/PUBLISHED/CONFERENCE/pdf/Ververidis2003b.pdf>`_
- Florian Eyben, Anton Batliner and Bjoern Schulle, Towards a standard set of acoustic features for the processing of emotion in speech, Acoustical society of America, `paper3 <https://asa.scitation.org/doi/pdf/10.1121/1.4739483>`_
- Aeluri Pramod Reddy and V Vijayarajan, Extraction of Emotions from Speech-A Survey, VIT University, International Journal of Applied Engineering Research, `paper4 <https://www.ripublication.com/ijaer17/ijaerv12n16_46.pdf>`_
- Emotional Speech Databases, `document <https://link.springer.com/content/pdf/bbm%3A978-90-481-3129-7%2F1.pdf>`_
- Expressive Synthetic Speech, http://emosamples.syntheticspeech.de/


Contributing
============

All contributions are welcome!
If you know a dataset that belongs here (see `criteria <https://github.com/SuperKogito/SER-datasets/blob/master/CONTRIBUTING.md#criteria>`_) but is not listed, please feel free to add it.
For more information on Contributing, please refer to `CONTRIBUTING.md <https://github.com/SuperKogito/SER-datasets/blob/master/CONTRIBUTING.md>`_.

If you notice a typo or a mistake, please `report this as an issue <https://github.com/SuperKogito/SER-datasets/issues/new>`_ and help us improve the quality of this list.

Disclaimer
===========

The maintainer and the contributors try their best to keep this list up-to-date, and to only include working links (using automated verification with the help of the `urlchecker-action <https://github.com/marketplace/actions/urlchecker-action>`_).
However, we cannot guarantee that all listed links are up-to-date. Read more in `DISCLAIMER.md <https://github.com/SuperKogito/SER-datasets/blob/master/DISCLAIMER.md>`_.


.. datasets

.. _`ASVP-ESD`: https://www.kaggle.com/datasets/dejolilandry/asvpesdspeech-nonspeech-emotional-utterances
.. _`ESD`: https://hltsingapore.github.io/ESD/
.. _`MuSe-CAR`: https://zenodo.org/record/4134758
.. _`MSP-Podcast corpus`: https://ecs.utdallas.edu/research/researchlabs/msp-lab/MSP-Podcast.html
.. _`emotiontts open db`: https://github.com/emotiontts/emotiontts_open_db
.. _`URDU-Dataset`: https://github.com/siddiquelatif/urdu-dataset
.. _`BAVED`: https://www.kaggle.com/a13x10/basic-arabic-vocal-emotions-dataset
.. _`VIVAE`: https://zenodo.org/record/4066235
.. _`SEWA`: https://db.sewaproject.eu/
.. _`MELD`: https://affective-meld.github.io/
.. _`ShEMO`: https://github.com/mansourehk/ShEMO
.. _`DEMoS`: https://zenodo.org/record/2544829
.. _`AESDD`: http://m3c.web.auth.gr/research/aesdd-speech-emotion-recognition/
.. _`Emov-DB`: https://mega.nz/#F!KBp32apT!gLIgyWf9iQ-yqnWFUFuUHg!mYwUnI4K
.. _`RAVDESS`: https://zenodo.org/record/1188976#.XrC7a5NKjOR
.. _`JL corpus`: https://www.kaggle.com/tli725/jl-corpus
.. _`CaFE`: https://zenodo.org/record/1478765
.. _`EmoFilm`: https://zenodo.org/record/1326428
.. _`ANAD`: https://www.kaggle.com/suso172/arabic-natural-audio-dataset
.. _`EmoSynth`: https://zenodo.org/record/3727593
.. _`CMU-MOSEI`: https://www.amir-zadeh.com/datasets
.. _`CMU-MOSI`: https://www.amir-zadeh.com/datasets
.. _`MSP-IMPROV`: https://ecs.utdallas.edu/research/researchlabs/msp-lab/MSP-Improv.html
.. _`CREMA-D`: https://github.com/CheyneyComputerScience/CREMA-D
.. _`Example emotion videos used in investigation of emotion perception in schizophrenia`: https://espace.library.uq.edu.au/view/UQ:446541
.. _`EMOVO`: http://voice.fub.it/activities/corpora/emovo/index.html
.. _`RECOLA`: https://diuf.unifr.ch/main/diva/recola/download.html
.. _`GEMEP corpus`: https://www.unige.ch/cisa/gemep
.. _`OGVC`: https://sites.google.com/site/ogcorpus/home/en
.. _`LEGO corpus`: https://www.ultes.eu/ressources/lego-spoken-dialogue-corpus/
.. _`SEMAINE`: https://semaine-db.eu/
.. _`SAVEE`: http://kahlan.eps.surrey.ac.uk/savee/Database.html
.. _`TESS`: https://tspace.library.utoronto.ca/handle/1807/24487
.. _`EEKK`: https://metashare.ut.ee/repository/download/4d42d7a8463411e2a6e4005056b40024a19021a316b54b7fb707757d43d1a889/
.. _`IEMOCAP`: https://sail.usc.edu/iemocap/iemocap_release.htm
.. _`Keio-ESD`: http://research.nii.ac.jp/src/en/Keio-ESD.html
.. _`EMO-DB`: http://emodb.bilderbar.info/index-1280.html
.. _`eNTERFACE05`: http://www.enterface.net/enterface05/docs/results/databases/project2_database.zip
.. _`DES`: http://kom.aau.dk/~tb/speech/Emotions/

.. license

.. _`CC BY 4.0`: https://creativecommons.org/licenses/by/4.0/
.. _`CC BY-NC-SA 4.0`: https://creativecommons.org/licenses/by-nc-sa/4.0/
.. _`CC BY-NC-ND 4.0`: https://creativecommons.org/licenses/by-nc-nd/4.0/
.. _`CC-BY license`: https://metashare.ut.ee/repository/download/4d42d7a8463411e2a6e4005056b40024a19021a316b54b7fb707757d43d1a889/
.. _`Permitted Non-commercial Re-use with Acknowledgment`: https://guides.library.uq.edu.au/deposit_your_data/terms_and_conditions
.. _`Open Database License & Database Content License`: https://github.com/CheyneyComputerScience/CREMA-D/blob/master/LICENSE.txt
.. _`CC0 1.0`: https://creativecommons.org/publicdomain/zero/1.0/
.. _`CMU-MOSEI License`: https://github.com/A2Zadeh/CMU-MultimodalSDK/blob/master/LICENSE.txt
.. _`CMU-MOSI License`: https://github.com/A2Zadeh/CMU-MultimodalSDK/blob/master/LICENSE.txt
.. _`IEMOCAP license`: https://sail.usc.edu/iemocap/Data_Release_Form_IEMOCAP.pdf
.. _`SEWA EULA`: https://db.sewaproject.eu/media/doc/eula.pdf
.. _`Meld: GPL-3.0 License`: https://github.com/declare-lab/MELD/blob/master/LICENSE

.. papers

.. _`Seen And Unseen Emotional Style Transfer For Voice Conversion With A New Emotional Speech Dataset`: https://arxiv.org/pdf/2010.14794.pdf
.. _`The Multimodal Sentiment Analysis in Car Reviews (MuSe-CaR) Dataset: Collection, Insights and Improvements`: https://arxiv.org/pdf/2101.06053.pdf
.. _`The MSP-Conversation Corpus`: http://www.interspeech2020.org/index.php?m=content&c=index&a=show&catid=290&id=684
.. _`Cross Lingual Speech Emotion Recognition: Urdu vs. Western Languages`: https://arxiv.org/pdf/1812.10411.pdf
.. _`Estonian Emotional Speech Corpus`: https://www.researchgate.net/publication/261724574_Estonian_Emotional_Speech_Corpus_Release_1
.. _`IEMOCAP: Interactive emotional dyadic motion capture database`: https://sail.usc.edu/iemocap/Busso_2008_iemocap.pdf
.. _`A Database of German Emotional Speech`: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.130.8506&rep=rep1&type=pdf
.. _`SEWA DB: A Rich Database for Audio-Visual Emotion and Sentiment Research in the Wild`: https://arxiv.org/pdf/1901.02839.pdf
.. _`Documentation of the Danish Emotional Speech Database`: http://kom.aau.dk/~tb/speech/Emotions/des.pdf
.. _`EMOTIONAL SPEECH SYNTHESIS USING SUBSPACE CONSTRAINTS IN PROSODY`: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.420.8899&rep=rep1&type=pdf
.. _`Naturalistic emotional speech collectionparadigm with online game and its psychological and acoustical assessment`: https://www.jstage.jst.go.jp/article/ast/33/6/33_E1175/_pdf
.. _`EMOVO Corpus: an Italian Emotional Speech Database`: https://core.ac.uk/download/pdf/53857389.pdf
.. _`The eNTERFACE’05 Audio-Visual Emotion Database`: http://poseidon.csd.auth.gr/papers/PUBLISHED/CONFERENCE/pdf/Martin06a.pdf
.. _`Arabic Natural Audio Dataset`: https://data.mendeley.com/datasets/xm232yxf7t/1
.. _`Introducing the Geneva Multimodal Expression Corpus for Experimental Research on Emotion Perception`: https://www.researchgate.net/publication/51796867_Introducing_the_Geneva_Multimodal_Expression_Corpus_for_Experimental_Research_on_Emotion_Perception
.. _`Speech Emotion Recognition for Performance Interaction`: https://www.researchgate.net/publication/326005164_Speech_Emotion_Recognition_for_Performance_Interaction
.. _`MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations`: https://arxiv.org/pdf/1810.02508.pdf
.. _`BEHAVIOURAL FINDINGS FROM THE TORONTO EMOTIONAL SPEECH SET`: https://www.semanticscholar.org/paper/BEHAVIOURAL-FINDINGS-FROM-THE-TORONTO-EMOTIONAL-SET-Dupuis-Pichora-Fuller/d7f746b3aee801a353b6929a65d9a34a68e71c6f/figure/2
.. _`CREMA-D: Crowd-sourced Emotional Multimodal Actors Dataset`: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4313618/
.. _`DEMoS: An Italian emotional speech corpus. Elicitation methods, machine learning, and perception`: https://link.springer.com/epdf/10.1007/s10579-019-09450-y?author_access_token=5pf0w_D4k9z28TM6n4PbVPe4RwlQNchNByi7wbcMAY5hiA-aXzXNbZYfsMDDq2CdHD-w5ArAxIwlsk2nC_26pSyEAcu1xlKJ1c9m3JZj2ZlFmlVoCZUTcG3Hq2_2ozMLo3Hq3Y0CHzLdTxihQwch5Q%3D%3D
.. _`A Parameterized and Annotated Spoken Dialog Corpus of the CMU Let’s Go Bus Information System`: http://www.lrec-conf.org/proceedings/lrec2012/pdf/333_Paper.pdf
.. _`Introducing the RECOLA Multimodal Corpus of Remote Collaborative and Affective Interactions`: https://drive.google.com/file/d/0B2V_I9XKBODhNENKUnZWNFdVXzQ/view
.. _`Multimodal Emotion Recognition`: http://personal.ee.surrey.ac.uk/Personal/P.Jackson/pub/ma10/HaqJackson_MachineAudition10_approved.pdf
.. _`The Perceived Emotion of Isolated Synthetic Audio: The EmoSynth Dataset and Results`: https://dl.acm.org/doi/10.1145/3243274.3243277
.. _`MSP-IMPROV: An Acted Corpus of Dyadic Interactions to Study Emotion Perception`: https://ecs.utdallas.edu/research/researchlabs/msp-lab/publications/Busso_2017.pdf
.. _`Multi-attention Recurrent Network for Human Communication Comprehension`: https://arxiv.org/pdf/1802.00923.pdf
.. _`Categorical vs Dimensional Perception of Italian Emotional Speech`: https://pdfs.semanticscholar.org/e70e/fcf7f5b4c366a7b7e2c16267d7f7691a5391.pdf
.. _`Multi-attention Recurrent Network for Human Communication Comprehension`: https://arxiv.org/pdf/1802.00923.pdf
.. _`ShEMO: a large-scale validated database for Persian speech emotion detection`: https://link.springer.com/article/10.1007/s10579-018-9427-x
.. _`The emotional voices database: Towards controlling the emotion dimension in voice generation systems`: https://arxiv.org/pdf/1806.09514.pdf
.. _`The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English`: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0196391
.. _`An Open Source Emotional Speech Corpus for Human Robot Interaction Applications`: https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1349.pdf
.. _`The SEMAINE Database: Annotated Multimodal Records of Emotionally Colored Conversations between a Person and a Limited Agent`: https://ieeexplore.ieee.org/document/5959155
