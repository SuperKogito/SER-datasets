***Speech Emotion Recognition (SER) Datasets:*** *A collection of datasets (count=57) for the purpose of emotion recognition/detection in speech.
The table is chronologically ordered and includes a description of the content of each dataset along with the emotions included.
The table can be browsed, sorted and searched under https://superkogito.github.io/SER-datasets/*
| Dataset                                                                                                                                           | Year            | Content                                                                                                                                                                                                                                                                          | Emotions                                                                                                                                                                                                                                                                     | Format                        | Size                 | Language                                                          | Paper                                                                                                                                                                                                                                                                                                                                                     | Access                    | License                                                                                                                                   |
|:--------------------------------------------------------------------------------------------------------------------------------------------------|:----------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------|:---------------------|:------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------|:------------------------------------------------------------------------------------------------------------------------------------------|
| <sub>[Hi, KIA](https://zenodo.org/records/7091465)</sub>                                                                                          | <sub>2022</sub> | <sub>A shared short Wakeup Word database focusing on perceived emotion in speech The dataset contains 488 Wakeup Word speech</sub>                                                                                                                                               | <sub>angry, happy, sad, neutral</sub>                                                                                                                                                                                                                                        | <sub>Audio</sub>              | <sub>0.75 GB</sub>   | <sub>Korean</sub>                                                 | <sub>[Hi, KIA: A Speech Emotion Recognition Dataset for Wake-Up Words](https://arxiv.org/abs/2211.03371)</sub>                                                                                                                                                                                                                                            | <sub>Open</sub>           | <sub>[CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)</sub>                                                                |
| <sub>[Emozionalmente](https://zenodo.org/records/6569824)</sub>                                                                                   | <sub>2022</sub> | <sub>6902 labeled samples acted out by 431 amateur actors while verbalizing 18 different sentences</sub>                                                                                                                                                                         | <sub>anger, disgust, fear, joy, sadness, surprise, neutral</sub>                                                                                                                                                                                                             | <sub>Audio</sub>              | <sub>0.581 GB</sub>  | <sub>Italian</sub>                                                | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)</sub>                                                                      |
| <sub>[Kannada](https://zenodo.org/records/6345107)</sub>                                                                                          | <sub>2022</sub> | <sub>468 audio samples, six different sentences, pronounced by thirteen people (four male and nine female), in five basic emotions plus one neutral emotion</sub>                                                                                                                | <sub>Anger, Sadness, Surprise, Happiness, Fear, Neutral</sub>                                                                                                                                                                                                                | <sub>Audio</sub>              | <sub>0.1661 GB</sub> | <sub>Kannada</sub>                                                | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)</sub>                                                                      |
| <sub>[emoUERJ](https://zenodo.org/records/5427549)</sub>                                                                                          | <sub>2021</sub> | <sub>Ten sentences from eight actors, equally divided between genders, and they were free to choose the phrases for record audios in four emotions (377 audios). </sub>                                                                                                          | <sub>happiness, anger, sadness or neutral</sub>                                                                                                                                                                                                                              | <sub>Audio</sub>              | <sub>0.1051 GB</sub> | <sub>Portuguese (Brazilian)</sub>                                 | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)</sub>                                                                      |
| <sub>[ESCorpus-PE](https://zenodo.org/records/5793223)</sub>                                                                                      | <sub>2021</sub> | <sub>Spanish peruvian speech gathered from Spanish interviews, TV reports, political debate and testimonials. It contains 3749 utterances, 80 speakers (44 male and 36 female), created from Youtube audios</sub>                                                                | <sub>Valence, Arousal and Dominance</sub>                                                                                                                                                                                                                                    | <sub>Audio</sub>              | <sub>1.9 GB</sub>    | <sub>Spanish (Peruvian)</sub>                                     | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>[CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)</sub>                                                                |
| <sub>[SUBSECO](https://zenodo.org/record/6339787)</sub>                                                                                           | <sub>2021</sub> | <sub>7000 sentence-level utterances of the Bangla language, 20 professional actors (10 males and 10 females), recordings, 10 sentences for 7 target emotions.</sub>                                                                                                              | <sub>Anger, Disgust, Fear, Happiness, Neutral, Sadness and Surprise</sub>                                                                                                                                                                                                    | <sub>Audio</sub>              | <sub>1.7 GB</sub>    | <sub>English</sub>                                                | <sub>[SUST Bangla Emotional Speech Corpus (SUBESCO): An audio-only emotional speech corpus for Bangla](https://doi.org/10.1371/journal.pone.0250173)</sub>                                                                                                                                                                                                | <sub>Open</sub>           | <sub>[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)</sub>                                                                      |
| <sub>[Audio-Speech-Sentiment](https://www.kaggle.com/imsparsh/audio-speech-sentiment-analysis)</sub>                                              | <sub>2021</sub> | <sub>Audio Speech Sentiment Dataset</sub>                                                                                                                                                                                                                                        | <sub>4 emotions provides audio recordings of spoken sentences for anger, happiness, sadness, and neutral emotions.</sub>                                                                                                                                                     | <sub>Audio</sub>              | <sub>1.1 GB</sub>    | <sub>English</sub>                                                | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>[CC0: Public Domain](https://creativecommons.org/publicdomain/zero/1.0/)</sub>                                                       |
| <sub>[Quechua-SER](https://figshare.com/articles/media/Quechua_Collao_for_Speech_Emotion_Recognition/20292516)</sub>                              | <sub>2022</sub> | <sub>12420 audio recordings (~15 hours) and their transcriptions by 7 native speakers.</sub>                                                                                                                                                                                     | <sub>Emotional labels using dimensions: valence, arousal, and dominance.</sub>                                                                                                                                                                                               | <sub>Audio</sub>              | <sub>3.53 GB</sub>   | <sub>Quechua Collao</sub>                                         | <sub>[A speech corpus of Quechua Collao for automatic dimensional emotion recognition](https://www.nature.com/articles/s41597-022-01855-9)</sub>                                                                                                                                                                                                          | <sub>Open</sub>           | <sub>[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)</sub>                                                                      |
| <sub>[MESD](https://data.mendeley.com/datasets/cy34mh68j9/5)</sub>                                                                                | <sub>2022</sub> | <sub>864 audio files of single-word emotional utterances with Mexican cultural shaping.</sub>                                                                                                                                                                                    | <sub>6 emotions provides single-word utterances for anger, disgust, fear, happiness, neutral, and sadness.</sub>                                                                                                                                                             | <sub>Audio</sub>              | <sub>0.097 GB</sub>  | <sub>Spanish (Mexican)</sub>                                      | <sub>[The Mexican Emotional Speech Database (MESD): elaboration and assessment based on machine learning](https://pubmed.ncbi.nlm.nih.gov/34891601/)</sub>                                                                                                                                                                                                | <sub>Open</sub>           | <sub>[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)</sub>                                                                      |
| <sub>[SyntAct](https://zenodo.org/record/6573016#.ZAjy_9LMJpj)</sub>                                                                              | <sub>2022</sub> | <sub>Synthesized database of three basic emotions and neutral expression based on rule-based manipulation for a diphone synthesizer which we release to the public </sub>                                                                                                        | <sub>997 utterances including 6 emotions: angry, bored, happy, neutral, sad and scared</sub>                                                                                                                                                                                 | <sub>Audio</sub>              | <sub>0.941 GB</sub>  | <sub>German</sub>                                                 | <sub>[SyntAct: A Synthesized Database of Basic Emotions](http://felix.syntheticspeech.de/publications/synthetic_database.pdf)</sub>                                                                                                                                                                                                                       | <sub>Open</sub>           | <sub>[CC BY-SA 4.0](https://creativecommons.org/licenses/by/4.0)</sub>                                                                    |
| <sub>[LSSED](https://github.com/tobefans/LSSED)</sub>                                                                                             | <sub>2021</sub> | <sub>LSSED: A Large-Scale Dataset and Benchmark for Speech Emotion Recognition</sub>                                                                                                                                                                                             | <sub>Anger, happiness, sadness, disappointment, boredom, disgust, excitement, fear, surprise, normal, and other.</sub>                                                                                                                                                       | <sub>Audio</sub>              | <sub>90 GB</sub>     | <sub>English</sub>                                                | <sub>[LSSED: A Large-Scale Spanish Emotional Speech Database for Speech Processing and Machine Learning](https://arxiv.org/abs/2102.01754)</sub>                                                                                                                                                                                                          | <sub>Restricted</sub>     | <sub>[-](https://github.com/tobefans/LSSED/blob/main/EULA.pdf)</sub>                                                                      |
| <sub>[MLEnd](https://www.kaggle.com/datasets/jesusrequena/mlend-spoken-numerals)</sub>                                                            | <sub>2021</sub> | <sub>~32700 audio recordings files produced by 154 speakers. Each audio recording corresponds to one English numeral (from "zero" to "billion")</sub>                                                                                                                            | <sub>Intonations: neutral, bored, excited and question</sub>                                                                                                                                                                                                                 | <sub>Audio</sub>              | <sub>2.27 GB</sub>   | <sub>--</sub>                                                     | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>Unknown</sub>                                                                                                                        |
| <sub>[ASVP-ESD](https://www.kaggle.com/datasets/dejolilandry/asvpesdspeech-nonspeech-emotional-utterances)</sub>                                  | <sub>2021</sub> | <sub>~13285 audio files collected from movies, tv shows and youtube containing speech and non-speech.</sub>                                                                                                                                                                      | <sub>12 different natural emotions (boredom, neutral, happiness, sadness, anger, fear, surprise, disgust, excitement, pleasure, pain, disappointment) with 2 levels of intensity.</sub>                                                                                      | <sub>Audio</sub>              | <sub>2 GB</sub>      | <sub>Chinese, English, French, Russian and others</sub>           | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>Unknown</sub>                                                                                                                        |
| <sub>[ESD](https://hltsingapore.github.io/ESD/)</sub>                                                                                             | <sub>2021</sub> | <sub>29 hours, 3500 sentences, by 10 native English speakers and 10 native Chinese speakers.</sub>                                                                                                                                                                               | <sub>5 emotions: angry, happy, neutral, sad, and surprise.</sub>                                                                                                                                                                                                             | <sub>Audio,  Text</sub>       | <sub>2.4 GB</sub>    | <sub>Chinese, English</sub>                                       | <sub>[Seen And Unseen Emotional Style Transfer For Voice Conversion With A New Emotional Speech Dataset](https://arxiv.org/pdf/2010.14794.pdf)</sub>                                                                                                                                                                                                      | <sub>Open</sub>           | <sub>Academic License</sub>                                                                                                               |
| <sub>[MuSe-CAR](https://zenodo.org/record/4134758)</sub>                                                                                          | <sub>2021</sub> | <sub>40 hours, 6,000+ recordings of 25,000+ sentences by 70+ English speakers (see db link for details).</sub>                                                                                                                                                                   | <sub>continuous emotion dimensions characterized using valence, arousal, and trustworthiness.</sub>                                                                                                                                                                          | <sub>Audio, Video, Text</sub> | <sub>15 GB</sub>     | <sub>English</sub>                                                | <sub>[The Multimodal Sentiment Analysis in Car Reviews (MuSe-CaR) Dataset: Collection, Insights and Improvements](https://arxiv.org/pdf/2101.06053.pdf)</sub>                                                                                                                                                                                             | <sub>Restricted</sub>     | <sub>Academic License & Commercial License</sub>                                                                                          |
| <sub>[THAI SER](https://github.com/vistec-AI/dataset-releases/releases/tag/v1)</sub>                                                              | <sub>2021</sub> | <sub>The recordings are 41 hours, 36 minutes long (27,854 utterances), and were performed by 200 professional actors (112 female, 88 male).</sub>                                                                                                                                | <sub>5 main emotions assigned to actors: Neutral, Anger, Happiness, Sadness, and Frustration.</sub>                                                                                                                                                                          | <sub>Audio</sub>              | <sub>12 GB</sub>     | <sub>Thai</sub>                                                   | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>[CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0)</sub>                                                                 |
| <sub>[French Emotional Speech Database - Or√©au](https://zenodo.org/records/4405783#.Yqjq_9JBxph)</sub>                                            | <sub>2020</sub> | <sub>79 utterances with 10 to 13 utterances pro emotion by 32 non-professional speakers.</sub>                                                                                                                                                                                   | <sub>7 emotions: sadness, anger, disgust, fear, surprise, joy, neutral.</sub>                                                                                                                                                                                                | <sub>Audio</sub>              | <sub>0.264 GB</sub>  | <sub>French</sub>                                                 | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)</sub>                                                                      |
| <sub>[Att-HACK ](http://www.openslr.org/88/)</sub>                                                                                                | <sub>2020</sub> | <sub>25 speakers interpreting 100 utterances in 4 social attitudes, with 3-5 repetitions each per attitude for a total of around 30 hours of speech.</sub>                                                                                                                       | <sub>expressive speech in French, 100 phrases with multiple versions (3 to 5) in four social attitudes (friendly, distant, dominant and seductive).</sub>                                                                                                                    | <sub>Audio</sub>              | <sub>6.6 GB</sub>    | <sub>French</sub>                                                 | <sub>[Att-HACK: An Expressive Speech Database with Social Attitudes](https://arxiv.org/abs/2004.04410)</sub>                                                                                                                                                                                                                                              | <sub>Open</sub>           | <sub>[CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)</sub>                                                          |
| <sub>[MSP-Podcast corpus](https://ecs.utdallas.edu/research/researchlabs/msp-lab/MSP-Podcast.html)</sub>                                          | <sub>2020</sub> | <sub>100 hours by over 100 speakers (see db link for details).</sub>                                                                                                                                                                                                             | <sub>This corpus is annotated with emotional labels using attribute-based descriptors (activation, dominance and valence) and categorical labels (anger, happiness, sadness, disgust, surprised, fear, contempt, neutral and other).</sub>                                   | <sub>Audio</sub>              | <sub>13.4 GB</sub>   | <sub>English</sub>                                                | <sub>[The MSP-Conversation Corpus](http://www.interspeech2020.org/index.php?m=content&c=index&a=show&catid=290&id=684)</sub>                                                                                                                                                                                                                              | <sub>Restricted</sub>     | <sub>Academic License & Commercial License</sub>                                                                                          |
| <sub>[BEASC](https://doi.org/10.6084/m9.figshare.12498033)</sub>                                                                                  | <sub>2020</sub> | <sub>Bangla Emotional Audio-Speech Corpus</sub>                                                                                                                                                                                                                                  | <sub>6 emotions provides Bangla spoken utterances for anger, happiness, sadness, fear, surprise, and neutral.</sub>                                                                                                                                                          | <sub>Audio</sub>              | <sub>9 GB</sub>      | <sub>Bangla</sub>                                                 | <sub>[BEASC: Bangla Emotional Audio-Speech Corpus - A Speech Emotion Recognition Corpus for the Low-Resource Bangla Language](https://easy.dans.knaw.nl/ui/datasets/id/easy-dataset:236649)</sub>                                                                                                                                                         | <sub>Open</sub>           | <sub>[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)</sub>                                                                      |
| <sub>[emotiontts open db](https://github.com/emotiontts/emotiontts_open_db)</sub>                                                                 | <sub>2020</sub> | <sub>Recordings and their associated transcriptions by a diverse group of speakers.</sub>                                                                                                                                                                                        | <sub>4 emotions: general, joy, anger, and sadness.</sub>                                                                                                                                                                                                                     | <sub>Audio, Text</sub>        | <sub>--</sub>        | <sub>Korean</sub>                                                 | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Partially open</sub> | <sub>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)</sub>                                                          |
| <sub>[URDU-Dataset](https://github.com/siddiquelatif/urdu-dataset)</sub>                                                                          | <sub>2020</sub> | <sub>400 utterances by 38 speakers (27 male and 11 female).</sub>                                                                                                                                                                                                                | <sub>4 emotions: angry, happy, neutral, and sad.</sub>                                                                                                                                                                                                                       | <sub>Audio</sub>              | <sub>0.072 GB</sub>  | <sub>Urdu</sub>                                                   | <sub>[Cross Lingual Speech Emotion Recognition: Urdu vs. Western Languages](https://arxiv.org/pdf/1812.10411.pdf)</sub>                                                                                                                                                                                                                                   | <sub>Open</sub>           | <sub>--</sub>                                                                                                                             |
| <sub>[BAVED](https://www.kaggle.com/a13x10/basic-arabic-vocal-emotions-dataset)</sub>                                                             | <sub>2020</sub> | <sub>1935 recording by 61 speakers (45 male and 16 female).</sub>                                                                                                                                                                                                                | <sub>3 levels of emotion.</sub>                                                                                                                                                                                                                                              | <sub>Audio</sub>              | <sub>0.195 GB</sub>  | <sub>Arabic</sub>                                                 | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>--</sub>                                                                                                                             |
| <sub>[VIVAE](https://zenodo.org/record/4066235)</sub>                                                                                             | <sub>2020</sub> | <sub>non-speech, 1085 audio file by 11 speakers.</sub>                                                                                                                                                                                                                           | <sub>non-speech 6 emotions: achievement, anger, fear, pain, pleasure, and surprise with 3 emotional intensities (low, moderate, strong, peak).</sub>                                                                                                                         | <sub>Audio</sub>              | <sub>0.0935 GB</sub> | <sub>Nonverbal (English)</sub>                                    | <sub>[The Variably Intense Vocalizations of Affect and Emotion (VIVAE) corpus prompts new perspective on nonspeech perception](http://dx.doi.org/10.1037/emo0001048)</sub>                                                                                                                                                                                | <sub>Restricted</sub>     | <sub>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)</sub>                                                          |
| <sub>[PMEmo](https://github.com/HuiZhangDB/PMEmo)</sub>                                                                                           | <sub>2019</sub> | <sub>Dataset containing emotion annotations of 794 songs as well as the simultaneous electrodermal activity (EDA) signals. A Music Emotion Experiment was well-designed for collecting the affective-annotated music corpus of high quality, which recruited 457 subjects.</sub> | <sub>Valence, Arousal</sub>                                                                                                                                                                                                                                                  | <sub>Audio, EDA</sub>         | <sub>1.3 GB</sub>    | <sub>Chinese, English</sub>                                       | <sub>[The PMEmo Dataset for Music Emotion Recognition](https://dl.acm.org/doi/10.1145/3206025.3206037)</sub>                                                                                                                                                                                                                                              | <sub>Open</sub>           | <sub>[CC BY-SA 4.0](https://huisblog.cn/PMEmo//)</sub>                                                                                    |
| <sub>[SEWA](https://db.sewaproject.eu/)</sub>                                                                                                     | <sub>2019</sub> | <sub>more than 2000 minutes of audio-visual data of 398 people (201 male and 197 female) coming from 6 cultures.</sub>                                                                                                                                                           | <sub>emotions are characterized using valence and arousal.</sub>                                                                                                                                                                                                             | <sub>Audio, Video</sub>       | <sub>--</sub>        | <sub>Chinese, English, German, Greek, Hungarian and Serbian</sub> | <sub>[SEWA DB: A Rich Database for Audio-Visual Emotion and Sentiment Research in the Wild](https://arxiv.org/pdf/1901.02839.pdf)</sub>                                                                                                                                                                                                                   | <sub>Restricted</sub>     | <sub>[SEWA EULA](https://db.sewaproject.eu/media/doc/eula.pdf)</sub>                                                                      |
| <sub>[MELD](https://affective-meld.github.io/)</sub>                                                                                              | <sub>2019</sub> | <sub>1400 dialogues and 14000 utterances from Friends TV series  by multiple speakers.</sub>                                                                                                                                                                                     | <sub>7 emotions: Anger, disgust, sadness, joy, neutral, surprise and fear.  MELD also has sentiment (positive, negative and neutral) annotation  for each utterance.</sub>                                                                                                   | <sub>Audio, Video, Text</sub> | <sub>10.1 GB</sub>   | <sub>English</sub>                                                | <sub>[MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations](https://arxiv.org/pdf/1810.02508.pdf)</sub>                                                                                                                                                                                                                        | <sub>Open</sub>           | <sub>[MELD: GPL-3.0 License](https://github.com/declare-lab/MELD/blob/master/LICENSE)</sub>                                               |
| <sub>[ShEMO](https://github.com/mansourehk/ShEMO)</sub>                                                                                           | <sub>2019</sub> | <sub>3000 semi-natural utterances, equivalent to 3 hours and 25 minutes of speech data from online radio plays by 87 native-Persian speakers.</sub>                                                                                                                              | <sub>6 emotions: anger, fear, happiness, sadness, neutral and surprise.</sub>                                                                                                                                                                                                | <sub>Audio</sub>              | <sub>0.101 GB</sub>  | <sub>Persian</sub>                                                | <sub>[ShEMO: a large-scale validated database for Persian speech emotion detection](https://link.springer.com/article/10.1007/s10579-018-9427-x)</sub>                                                                                                                                                                                                    | <sub>Open</sub>           | <sub>--</sub>                                                                                                                             |
| <sub>[DEMoS](https://zenodo.org/record/2544829)</sub>                                                                                             | <sub>2019</sub> | <sub>9365 emotional and 332 neutral samples produced by 68 native speakers (23 females, 45 males).</sub>                                                                                                                                                                         | <sub>7/6 emotions: anger, sadness, happiness, fear, surprise, disgust, and the secondary emotion guilt.</sub>                                                                                                                                                                | <sub>Audio</sub>              | <sub>2.5 GB</sub>    | <sub>Italian</sub>                                                | <sub>[DEMoS: An Italian emotional speech corpus. Elicitation methods, machine learning, and perception](https://link.springer.com/epdf/10.1007/s10579-019-09450-y?author_access_token=5pf0w_D4k9z28TM6n4PbVPe4RwlQNchNByi7wbcMAY5hiA-aXzXNbZYfsMDDq2CdHD-w5ArAxIwlsk2nC_26pSyEAcu1xlKJ1c9m3JZj2ZlFmlVoCZUTcG3Hq2_2ozMLo3Hq3Y0CHzLdTxihQwch5Q%3D%3D)</sub> | <sub>Restricted</sub>     | <sub>EULA: End User License Agreement</sub>                                                                                               |
| <sub>[AESDD](http://m3c.web.auth.gr/research/aesdd-speech-emotion-recognition/)</sub>                                                             | <sub>2018</sub> | <sub>around 500 utterances by a diverse group of actors (over 5 actors) siumlating various emotions.</sub>                                                                                                                                                                       | <sub>5 emotions: anger, disgust, fear, happiness, and sadness.</sub>                                                                                                                                                                                                         | <sub>Audio</sub>              | <sub>0.392 GB</sub>  | <sub>Greek</sub>                                                  | <sub>[Speech Emotion Recognition for Performance Interaction](https://www.researchgate.net/publication/326005164_Speech_Emotion_Recognition_for_Performance_Interaction)</sub>                                                                                                                                                                            | <sub>Open</sub>           | <sub>--</sub>                                                                                                                             |
| <sub>[Emov-DB](https://mega.nz/#F!KBp32apT!gLIgyWf9iQ-yqnWFUFuUHg!mYwUnI4K)</sub>                                                                 | <sub>2018</sub> | <sub>Recordings for 4 speakers- 2 males and 2 females.</sub>                                                                                                                                                                                                                     | <sub>The emotional styles are neutral, sleepiness, anger, disgust and amused.</sub>                                                                                                                                                                                          | <sub>Audio</sub>              | <sub>5.88 GB</sub>   | <sub>English</sub>                                                | <sub>[The emotional voices database: Towards controlling the emotion dimension in voice generation systems](https://arxiv.org/pdf/1806.09514.pdf)</sub>                                                                                                                                                                                                   | <sub>Open</sub>           | <sub>--</sub>                                                                                                                             |
| <sub>[RAVDESS](https://zenodo.org/record/1188976#.XrC7a5NKjOR)</sub>                                                                              | <sub>2018</sub> | <sub>7356 recordings by 24 actors.</sub>                                                                                                                                                                                                                                         | <sub>7 emotions: calm, happy, sad, angry, fearful, surprise, and disgust</sub>                                                                                                                                                                                               | <sub>Audio, Video</sub>       | <sub>24.8 GB</sub>   | <sub>English</sub>                                                | <sub>[The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0196391)</sub>                                                                                                     | <sub>Open</sub>           | <sub>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)</sub>                                                          |
| <sub>[JL corpus](https://www.kaggle.com/tli725/jl-corpus)</sub>                                                                                   | <sub>2018</sub> | <sub>2400 recording of 240 sentences by 4 actors (2 males and 2 females).</sub>                                                                                                                                                                                                  | <sub>5 primary emotions: angry, sad, neutral, happy, excited. 5 secondary emotions: anxious, apologetic, pensive, worried, enthusiastic.</sub>                                                                                                                               | <sub>Audio</sub>              | <sub>1.9 GB</sub>    | <sub>English</sub>                                                | <sub>[An Open Source Emotional Speech Corpus for Human Robot Interaction Applications](https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1349.pdf)</sub>                                                                                                                                                                                          | <sub>Open</sub>           | <sub>[CC0 1.0](https://creativecommons.org/publicdomain/zero/1.0/)</sub>                                                                  |
| <sub>[CaFE](https://zenodo.org/record/1478765)</sub>                                                                                              | <sub>2018</sub> | <sub>6 different sentences by 12 speakers (6 fmelaes + 6 males).</sub>                                                                                                                                                                                                           | <sub>7 emotions: happy, sad, angry, fearful, surprise, disgust and neutral. Each emotion is acted in 2 different intensities.</sub>                                                                                                                                          | <sub>Audio</sub>              | <sub>2 GB</sub>      | <sub>French (Canadian)</sub>                                      | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)</sub>                                                          |
| <sub>[EmoFilm](https://zenodo.org/record/1326428)</sub>                                                                                           | <sub>2018</sub> | <sub>1115 audio instances sentences extracted from various films.</sub>                                                                                                                                                                                                          | <sub>5 emotions: anger, contempt, happiness, fear, and sadness.</sub>                                                                                                                                                                                                        | <sub>Audio</sub>              | <sub>0.277 GB</sub>  | <sub>English, Italian, Spanish</sub>                              | <sub>[Categorical vs Dimensional Perception of Italian Emotional Speech](https://pdfs.semanticscholar.org/e70e/fcf7f5b4c366a7b7e2c16267d7f7691a5391.pdf)</sub>                                                                                                                                                                                            | <sub>Restricted</sub>     | <sub>EULA: End User License Agreement</sub>                                                                                               |
| <sub>[ANAD](https://www.kaggle.com/suso172/arabic-natural-audio-dataset)</sub>                                                                    | <sub>2018</sub> | <sub>1384 recording by multiple speakers.</sub>                                                                                                                                                                                                                                  | <sub>3 emotions: angry, happy, surprised.</sub>                                                                                                                                                                                                                              | <sub>Audio</sub>              | <sub>2 GB</sub>      | <sub>Arabic</sub>                                                 | <sub>[Arabic Natural Audio Dataset](https://data.mendeley.com/datasets/xm232yxf7t/1)</sub>                                                                                                                                                                                                                                                                | <sub>Open</sub>           | <sub>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)</sub>                                                          |
| <sub>[EmoSynth](https://zenodo.org/record/3727593)</sub>                                                                                          | <sub>2018</sub> | <sub>144 audio file labelled by 40 listeners.</sub>                                                                                                                                                                                                                              | <sub>Emotion (no speech) defined in regard of valence and arousal.</sub>                                                                                                                                                                                                     | <sub>Audio</sub>              | <sub>0.1034 GB</sub> | <sub>--</sub>                                                     | <sub>[The Perceived Emotion of Isolated Synthetic Audio: The EmoSynth Dataset and Results](https://dl.acm.org/doi/10.1145/3243274.3243277)</sub>                                                                                                                                                                                                          | <sub>Open</sub>           | <sub>[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)</sub>                                                                      |
| <sub>[CMU-MOSEI](https://www.amir-zadeh.com/datasets)</sub>                                                                                       | <sub>2018</sub> | <sub>65 hours of annotated video from more than 1000 speakers and 250 topics.</sub>                                                                                                                                                                                              | <sub>6 Emotion (happiness, sadness, anger,fear, disgust, surprise) + Likert scale.</sub>                                                                                                                                                                                     | <sub>Audio, Video</sub>       | <sub>190.1 GB</sub>  | <sub>English</sub>                                                | <sub>[Multi-attention Recurrent Network for Human Communication Comprehension](https://arxiv.org/pdf/1802.00923.pdf)</sub>                                                                                                                                                                                                                                | <sub>Open</sub>           | <sub>[CMU-MOSEI License](https://github.com/A2Zadeh/CMU-MultimodalSDK/blob/master/LICENSE.txt)</sub>                                      |
| <sub>[VERBO](https://sites.google.com/view/verbodatabase/home)</sub>                                                                              | <sub>2018</sub> | <sub>14 different phrases by 12 speakers (6 female + 6 male) for a total of 1167 recordings.</sub>                                                                                                                                                                               | <sub>7 emotions: Happiness, Disgust, Fear, Neutral, Anger, Surprise, Sadness</sub>                                                                                                                                                                                           | <sub>Audio</sub>              | <sub>--</sub>        | <sub>Portuguese</sub>                                             | <sub>[VERBO: Voice Emotion Recognition dataBase in Portuguese Language](https://thescipub.com/pdf/jcssp.2018.1420.1430.pdf)</sub>                                                                                                                                                                                                                         | <sub>Restricted</sub>     | <sub>Available for research purposes only</sub>                                                                                           |
| <sub>[CMU-MOSI](https://www.amir-zadeh.com/datasets)</sub>                                                                                        | <sub>2017</sub> | <sub>2199 opinion utterances with annotated sentiment.</sub>                                                                                                                                                                                                                     | <sub>Sentiment annotated between very negative to very positive in seven Likert steps.</sub>                                                                                                                                                                                 | <sub>Audio, Video</sub>       | <sub>4.3 GB</sub>    | <sub>English</sub>                                                | <sub>[Multi-attention Recurrent Network for Human Communication Comprehension](https://arxiv.org/pdf/1802.00923.pdf)</sub>                                                                                                                                                                                                                                | <sub>Open</sub>           | <sub>[CMU-MOSI License](https://github.com/A2Zadeh/CMU-MultimodalSDK/blob/master/LICENSE.txt)</sub>                                       |
| <sub>[MSP-IMPROV](https://ecs.utdallas.edu/research/researchlabs/msp-lab/MSP-Improv.html)</sub>                                                   | <sub>2017</sub> | <sub>20 sentences by 12 actors.</sub>                                                                                                                                                                                                                                            | <sub>4 emotions: angry, sad, happy, neutral, other, without agreement</sub>                                                                                                                                                                                                  | <sub>Audio, Video</sub>       | <sub>3.4 GB</sub>    | <sub>English</sub>                                                | <sub>[MSP-IMPROV: An Acted Corpus of Dyadic Interactions to Study Emotion Perception](https://ecs.utdallas.edu/research/researchlabs/msp-lab/publications/Busso_2017.pdf)</sub>                                                                                                                                                                           | <sub>Restricted</sub>     | <sub>Academic License & Commercial License</sub>                                                                                          |
| <sub>[CREMA-D](https://github.com/CheyneyComputerScience/CREMA-D)</sub>                                                                           | <sub>2017</sub> | <sub>7442 clip of 12 sentences spoken by 91 actors (48 males and 43 females).</sub>                                                                                                                                                                                              | <sub>6 emotions: angry, disgusted, fearful, happy, neutral, and sad</sub>                                                                                                                                                                                                    | <sub>Audio, Video</sub>       | <sub>0.607 GB</sub>  | <sub>English</sub>                                                | <sub>[CREMA-D: Crowd-sourced Emotional Multimodal Actors Dataset](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4313618/)</sub>                                                                                                                                                                                                                            | <sub>Open</sub>           | <sub>[Open Database License & Database Content License](https://github.com/CheyneyComputerScience/CREMA-D/blob/master/LICENSE.txt)</sub>  |
| <sub>[Example emotion videos used in investigation of emotion perception in schizophrenia](https://espace.library.uq.edu.au/view/UQ:446541)</sub> | <sub>2017</sub> | <sub>6 videos:Two example videos from each emotion category (angry, happy and neutral) by one female speaker.</sub>                                                                                                                                                              | <sub>3 emotions: angry, happy and neutral.</sub>                                                                                                                                                                                                                             | <sub>Audio, Video</sub>       | <sub>0.063 GB</sub>  | <sub>English</sub>                                                | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>[Permitted Non-commercial Re-use with Acknowledgment](https://guides.library.uq.edu.au/deposit_your_data/terms_and_conditions)</sub> |
| <sub>[EMOVO](http://voice.fub.it/activities/corpora/emovo/index.html)</sub>                                                                       | <sub>2014</sub> | <sub>6 actors  who  played  14  sentences.</sub>                                                                                                                                                                                                                                 | <sub>6 emotions: disgust, fear, anger, joy, surprise, sadness.</sub>                                                                                                                                                                                                         | <sub>Audio</sub>              | <sub>0.355 GB</sub>  | <sub>Italian</sub>                                                | <sub>[EMOVO Corpus: an Italian Emotional Speech Database](https://core.ac.uk/download/pdf/53857389.pdf)</sub>                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>--</sub>                                                                                                                             |
| <sub>[RECOLA](https://diuf.unifr.ch/main/diva/recola/download.html)</sub>                                                                         | <sub>2013</sub> | <sub>3.8 hours of recordings by 46 participants.</sub>                                                                                                                                                                                                                           | <sub>negative and positive sentiment (valence and arousal).</sub>                                                                                                                                                                                                            | <sub>Audio, Video</sub>       | <sub>--</sub>        | <sub>--</sub>                                                     | <sub>[Introducing the RECOLA Multimodal Corpus of Remote Collaborative and Affective Interactions](https://drive.google.com/file/d/0B2V_I9XKBODhNENKUnZWNFdVXzQ/view)</sub>                                                                                                                                                                               | <sub>Restricted</sub>     | <sub>Academic License & Commercial License</sub>                                                                                          |
| <sub>[GEMEP corpus](https://www.unige.ch/cisa/gemep)</sub>                                                                                        | <sub>2012</sub> | <sub>Videos10 actors portraying 10 states.</sub>                                                                                                                                                                                                                                 | <sub>12 emotions: amusement, anxiety, cold anger (irritation), despair, hot anger (rage),  fear (panic), interest, joy (elation), pleasure(sensory), pride, relief, and sadness. Plus, 5 additional emotions: admiration, contempt, disgust, surprise, and tenderness.</sub> | <sub>Audio, Video</sub>       | <sub>--</sub>        | <sub>French</sub>                                                 | <sub>[Introducing the Geneva Multimodal Expression Corpus for Experimental Research on Emotion Perception](https://www.researchgate.net/publication/51796867_Introducing_the_Geneva_Multimodal_Expression_Corpus_for_Experimental_Research_on_Emotion_Perception)</sub>                                                                                   | <sub>Restricted</sub>     | <sub>--</sub>                                                                                                                             |
| <sub>[OGVC](https://sites.google.com/site/ogcorpus/home/en)</sub>                                                                                 | <sub>2012</sub> | <sub>9114 spontaneous utterances and 2656 acted utterances by 4 professional actors (two male and two female).</sub>                                                                                                                                                             | <sub>9 emotional states: fear, surprise, sadness, disgust, anger, anticipation, joy, acceptance and the neutral state.</sub>                                                                                                                                                 | <sub>Audio</sub>              | <sub>5.3 GB</sub>    | <sub>Japanese</sub>                                               | <sub>[Naturalistic emotional speech collectionparadigm with online game and its psychological and acoustical assessment](https://www.jstage.jst.go.jp/article/ast/33/6/33_E1175/_pdf)</sub>                                                                                                                                                               | <sub>Restricted</sub>     | <sub>--</sub>                                                                                                                             |
| <sub>[LEGO corpus](https://www.ultes.eu/ressources/lego-spoken-dialogue-corpus/)</sub>                                                            | <sub>2012</sub> | <sub>347 dialogs with 9,083 system-user exchanges.</sub>                                                                                                                                                                                                                         | <sub>Emotions classified as garbage, non-angry, slightly angry and very angry.</sub>                                                                                                                                                                                         | <sub>Audio</sub>              | <sub>1.1 GB</sub>    | <sub>--</sub>                                                     | <sub>[A Parameterized and Annotated Spoken Dialog Corpus of the CMU Let‚Äôs Go Bus Information System](http://www.lrec-conf.org/proceedings/lrec2012/pdf/333_Paper.pdf)</sub>                                                                                                                                                                               | <sub>Open</sub>           | <sub>License available with the data. Free of charges for research purposes only.</sub>                                                   |
| <sub>[SEMAINE](https://semaine-db.eu/)</sub>                                                                                                      | <sub>2012</sub> | <sub>95 dyadic conversations from 21 subjects. Each subject converses with another playing one of four characters with emotions.</sub>                                                                                                                                           | <sub>5 FeelTrace annotations: activation, valence, dominance, power, intensity</sub>                                                                                                                                                                                         | <sub>Audio, Video, Text</sub> | <sub>104 GB</sub>    | <sub>English</sub>                                                | <sub>[The SEMAINE Database: Annotated Multimodal Records of Emotionally Colored Conversations between a Person and a Limited Agent](https://ieeexplore.ieee.org/document/5959155)</sub>                                                                                                                                                                   | <sub>Restricted</sub>     | <sub>Academic EULA</sub>                                                                                                                  |
| <sub>[SAVEE](http://kahlan.eps.surrey.ac.uk/savee/Database.html)</sub>                                                                            | <sub>2011</sub> | <sub>480 British English utterances by 4 males actors.</sub>                                                                                                                                                                                                                     | <sub>7 emotions: anger, disgust, fear, happiness, sadness, surprise and neutral.</sub>                                                                                                                                                                                       | <sub>Audio, Video</sub>       | <sub>--</sub>        | <sub>English (British)</sub>                                      | <sub>[Multimodal Emotion Recognition](http://personal.ee.surrey.ac.uk/Personal/P.Jackson/pub/ma10/HaqJackson_MachineAudition10_approved.pdf)</sub>                                                                                                                                                                                                        | <sub>Restricted</sub>     | <sub>Free of charges for research purposes only.</sub>                                                                                    |
| <sub>[TESS](https://tspace.library.utoronto.ca/handle/1807/24487)</sub>                                                                           | <sub>2010</sub> | <sub>2800 recording by 2 actresses.</sub>                                                                                                                                                                                                                                        | <sub>7 emotions: anger, disgust, fear, happiness, pleasant surprise, sadness, and neutral.</sub>                                                                                                                                                                             | <sub>Audio</sub>              | <sub>--</sub>        | <sub>English</sub>                                                | <sub>[BEHAVIOURAL FINDINGS FROM THE TORONTO EMOTIONAL SPEECH SET](https://www.semanticscholar.org/paper/BEHAVIOURAL-FINDINGS-FROM-THE-TORONTO-EMOTIONAL-SET-Dupuis-Pichora-Fuller/d7f746b3aee801a353b6929a65d9a34a68e71c6f/figure/2)</sub>                                                                                                                | <sub>Open</sub>           | <sub>[CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)</sub>                                                          |
| <sub>[EEKK](https://metashare.ut.ee/repository/download/4d42d7a8463411e2a6e4005056b40024a19021a316b54b7fb707757d43d1a889/)</sub>                  | <sub>2007</sub> | <sub>26 text passage read by 10 speakers.</sub>                                                                                                                                                                                                                                  | <sub>4 main emotions: joy, sadness, anger and neutral.</sub>                                                                                                                                                                                                                 | <sub>--</sub>                 | <sub>0.352 GB</sub>  | <sub>Estonian</sub>                                               | <sub>[Estonian Emotional Speech Corpus](https://www.researchgate.net/publication/261724574_Estonian_Emotional_Speech_Corpus_Release_1)</sub>                                                                                                                                                                                                              | <sub>Open</sub>           | <sub>[CC-BY license](https://metashare.ut.ee/repository/download/4d42d7a8463411e2a6e4005056b40024a19021a316b54b7fb707757d43d1a889/)</sub> |
| <sub>[IEMOCAP](https://sail.usc.edu/iemocap/iemocap_release.htm)</sub>                                                                            | <sub>2007</sub> | <sub>12 hours of audiovisual data by 10 actors in 5 sessions.</sub>                                                                                                                                                                                                              | <sub>Full: neutral state; happiness; sadness; anger; surprise; fear; disgust; frustration; excited; other. Balance 5 emotions: happiness, anger, sadness, frustration and neutral. Three dimensions: valence, arousal, dominance</sub>                                       | <sub>Audio, Video, Text</sub> | <sub>17.7 GB</sub>   | <sub>English</sub>                                                | <sub>[IEMOCAP: Interactive emotional dyadic motion capture database](https://sail.usc.edu/iemocap/Busso_2008_iemocap.pdf)</sub>                                                                                                                                                                                                                           | <sub>Restricted</sub>     | <sub>[IEMOCAP license](https://sail.usc.edu/iemocap/Data_Release_Form_IEMOCAP.pdf)</sub>                                                  |
| <sub>[Keio-ESD](http://research.nii.ac.jp/src/en/Keio-ESD.html)</sub>                                                                             | <sub>2006</sub> | <sub>A set of human speech with vocal emotion spoken by a Japanese male speaker.</sub>                                                                                                                                                                                           | <sub>47 emotions including angry, joyful, disgusting, downgrading, funny,  worried, gentle, relief, indignation, shameful, etc.</sub>                                                                                                                                        | <sub>Audio</sub>              | <sub>0.0435 GB</sub> | <sub>Japanese</sub>                                               | <sub>[EMOTIONAL SPEECH SYNTHESIS USING SUBSPACE CONSTRAINTS IN PROSODY](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.420.8899&rep=rep1&type=pdf)</sub>                                                                                                                                                                                        | <sub>Restricted</sub>     | <sub>Available for research purposes only.</sub>                                                                                          |
| <sub>[EMO-DB](http://emodb.bilderbar.info/index-1280.html)</sub>                                                                                  | <sub>2005</sub> | <sub>800 recording spoken by 10 actors (5 males and 5 females).</sub>                                                                                                                                                                                                            | <sub>7 emotions: anger, neutral, fear, boredom, happiness, sadness, disgust.</sub>                                                                                                                                                                                           | <sub>Audio</sub>              | <sub>0.049 GB</sub>  | <sub>German</sub>                                                 | <sub>[A Database of German Emotional Speech](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.130.8506&rep=rep1&type=pdf)</sub>                                                                                                                                                                                                                   | <sub>Open</sub>           | <sub>--</sub>                                                                                                                             |
| <sub>[eNTERFACE05](http://www.enterface.net/enterface05/docs/results/databases/project2_database.zip)</sub>                                       | <sub>2005</sub> | <sub>Videos by 42 subjects, coming from 14 different nationalities.</sub>                                                                                                                                                                                                        | <sub>6 emotions: anger, fear, surprise, happiness, sadness and disgust.</sub>                                                                                                                                                                                                | <sub>Audio, Video</sub>       | <sub>0.8 GB</sub>    | <sub>German</sub>                                                 | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>Free of charges for research purposes only.</sub>                                                                                    |
| <sub>[DES](http://kom.aau.dk/~tb/speech/Emotions/)</sub>                                                                                          | <sub>2002</sub> | <sub>4 speakers (2 males and 2 females).</sub>                                                                                                                                                                                                                                   | <sub>5 emotions: neutral,  surprise,  happiness,  sadness  and  anger</sub>                                                                                                                                                                                                  | <sub>--</sub>                 | <sub>--</sub>        | <sub>Danish</sub>                                                 | <sub>[Documentation of the Danish Emotional Speech Database](http://kom.aau.dk/~tb/speech/Emotions/des.pdf)</sub>                                                                                                                                                                                                                                         | <sub>--</sub>             | <sub>--</sub>                                                                                                                             |## References

- Swain, Monorama & Routray, Aurobinda & Kabisatpathy, Prithviraj, Databases, features and classifiers for speech emotion recognition: a review, International Journal of Speech Technology, [paper](https://www.researchgate.net/publication/322602563_Databases_features_and_classifiers_for_speech_emotion_recognition_a_review#pf19)
- Dimitrios Ververidis and Constantine Kotropoulos, A State of the Art Review on Emotional Speech Databases, Artificial Intelligence & Information Analysis Laboratory, Department of Informatics Aristotle, University of Thessaloniki, [paper](http://poseidon.csd.auth.gr/papers/PUBLISHED/CONFERENCE/pdf/Ververidis2003b.pdf)
- A. Pramod Reddy and V. Vijayarajan, Extraction of Emotions from Speech-A Survey, VIT University, International Journal of Applied Engineering Research, [paper](https://www.ripublication.com/ijaer17/ijaerv12n16_46.pdf)
- Emotional Speech Databases, [document](https://link.springer.com/content/pdf/bbm%3A978-90-481-3129-7%2F1.pdf)
- Expressive Synthetic Speech, [website](http://emosamples.syntheticspeech.de/)
- Towards a standard set of acoustic features for the processing of emotion in speech, Technical university Munich, [document](https://asa.scitation.org/doi/pdf/10.1121/1.4739483)


## Contribution

- All contributions are welcome! If you know a dataset that belongs here (see [criteria](https://github.com/SuperKogito/SER-datasets/blob/master/CONTRIBUTING.md#criteria)) but is not listed, please feel free to add it. For more information on Contributing, please refer to [CONTRIBUTING.md](https://github.com/SuperKogito/SER-datasets/blob/master/CONTRIBUTING.md).

-  If you notice a typo or a mistake, please [report this as an issue](https://github.com/SuperKogito/SER-datasets/issues/new) and help us improve the quality of this list.


## Disclaimer
- The mainter and the contributors try their best to keep this list up-to-date, and to only include working links (using automated verification with the help of the [urlchecker-action](https://github.com/marketplace/actions/urlchecker-action)). However, we cannot guarantee that all listed links are up-to-date. Read more in [DISCLAIMER.md](https://github.com/SuperKogito/SER-datasets/blob/master/DISCLAIMER.md).

## Recommended tools

- [Nkululeko](https://github.com/felixbur/nkululeko)  
This toolkit has a [data](https://github.com/felixbur/nkululeko/tree/main/data) directory with each python-preprocessing script that can load most datasets in this list. The processing script there will split the data into train, validation, and test sets, and save them as CSV files with file paths and labels. Then, you can make make experiments to detect emotions from speech using that dataset with Nkululeko or other tools.

- [ERTK](https://github.com/Strong-AI-Lab/emotion)  
Similar to Nkululeko, ERTK (emotion recognition toolkit) also has [dataset](https://github.com/Strong-AI-Lab/emotion/tree/master/datasets) directory that can load most datasets in this list.
