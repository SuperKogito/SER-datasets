***Spoken Emotion Recognition Datasets:*** *A collection of datasets (count=43) for the purpose of emotion recognition/detection in speech.
The table is chronologically ordered and includes a description of the content of each dataset along with the emotions included.
The table can be browsed, sorted and searched under https://superkogito.github.io/SER-datasets/*
| Dataset                                                                                                                                           | Year            | Content                                                                                                                                                                   | Emotions                                                                                                                                                                                                                                                                     | Format                        | Size                    | Language                                                          | Paper                                                                                                                                                                                                                                                                                                                                                     | Access                    | License                                                                                                                                   |
|:--------------------------------------------------------------------------------------------------------------------------------------------------|:----------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------|:------------------------|:------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------|:------------------------------------------------------------------------------------------------------------------------------------------|
| <sub>[MESD](https://data.mendeley.com/datasets/cy34mh68j9/5)</sub>                                                                                | <sub>2022</sub> | <sub>864 audio files of single-word emotional utterances with Mexican cultural shaping.</sub>                                                                             | <sub>6 emotions provides single-word utterances for anger, disgust, fear, happiness, neutral, and sadness.</sub>                                                                                                                                                             | <sub>Audio</sub>              | <sub>0,097 GB</sub>     | <sub>Spanish (Mexican)</sub>                                      | <sub>[The Mexican Emotional Speech Database (MESD): elaboration and assessment based on machine learning](https://pubmed.ncbi.nlm.nih.gov/34891601/)</sub>                                                                                                                                                                                                | <sub>Open</sub>           | <sub>[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)</sub>                                                                      |
| <sub>[SyntAct](https://zenodo.org/record/6573016#.ZAjy_9LMJpj)</sub>                                                                              | <sub>2022</sub> | <sub>Synthesized database of three basic emotions and neutral expression based on rule-based manipulation for a diphone synthesizer which we release to the public </sub> | <sub>997 utterances including 6 emotions: angry, bored, happy, neutral, sad and scared</sub>                                                                                                                                                                                 | <sub>Audio</sub>              | <sub>941 MB</sub>       | <sub>German</sub>                                                 | <sub>[SyntAct: A Synthesized Database of Basic Emotions](http://felix.syntheticspeech.de/publications/synthetic_database.pdf)</sub>                                                                                                                                                                                                                       | <sub>Open</sub>           | <sub>[CC BY-SA 4.0](https://creativecommons.org/licenses/by/4.0)</sub>                                                                    |
| <sub>[MLEnd](https://www.kaggle.com/datasets/jesusrequena/mlend-spoken-numerals)</sub>                                                            | <sub>2021</sub> | <sub>~32700 audio recordings files produced by 154 speakers. Each audio recording corresponds to one English numeral (from "zero" to "billion")</sub>                     | <sub>Intonations: neutral, bored, excited and question</sub>                                                                                                                                                                                                                 | <sub>Audio</sub>              | <sub>2.27 GB</sub>      | <sub>--</sub>                                                     | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>Unknown</sub>                                                                                                                        |
| <sub>[ASVP-ESD](https://www.kaggle.com/datasets/dejolilandry/asvpesdspeech-nonspeech-emotional-utterances)</sub>                                  | <sub>2021</sub> | <sub>~13285 audio files collected from movies, tv shows and youtube containing speech and non-speech.</sub>                                                               | <sub>12 different natural emotions (boredom, neutral, happiness, sadness, anger, fear, surprise, disgust, excitement, pleasure, pain, disappointment) with 2 levels of intensity.</sub>                                                                                      | <sub>Audio</sub>              | <sub>2 GB</sub>         | <sub>Chinese, English, French, Russian and others</sub>           | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>Unknown</sub>                                                                                                                        |
| <sub>[ESD](https://hltsingapore.github.io/ESD/)</sub>                                                                                             | <sub>2021</sub> | <sub>29 hours, 3500 sentences, by 10 native English speakers and 10 native Chinese speakers.</sub>                                                                        | <sub>5 emotions: angry, happy, neutral, sad, and surprise.</sub>                                                                                                                                                                                                             | <sub>Audio,  Text</sub>       | <sub>2.4 GB (zip)</sub> | <sub>Chinese, English</sub>                                       | <sub>[Seen And Unseen Emotional Style Transfer For Voice Conversion With A New Emotional Speech Dataset](https://arxiv.org/pdf/2010.14794.pdf)</sub>                                                                                                                                                                                                      | <sub>Open</sub>           | <sub>Academic License</sub>                                                                                                               |
| <sub>[MuSe-CAR](https://zenodo.org/record/4134758)</sub>                                                                                          | <sub>2021</sub> | <sub>40 hours, 6,000+ recordings of 25,000+ sentences by 70+ English speakers (see db link for details).</sub>                                                            | <sub>continuous emotion dimensions characterized using valence, arousal, and trustworthiness.</sub>                                                                                                                                                                          | <sub>Audio, Video, Text</sub> | <sub>15 GB</sub>        | <sub>English</sub>                                                | <sub>[The Multimodal Sentiment Analysis in Car Reviews (MuSe-CaR) Dataset: Collection, Insights and Improvements](https://arxiv.org/pdf/2101.06053.pdf)</sub>                                                                                                                                                                                             | <sub>Restricted</sub>     | <sub>Academic License & Commercial License</sub>                                                                                          |
| <sub>[MSP-Podcast corpus](https://ecs.utdallas.edu/research/researchlabs/msp-lab/MSP-Podcast.html)</sub>                                          | <sub>2020</sub> | <sub>100 hours by over 100 speakers (see db link for details).</sub>                                                                                                      | <sub>This corpus is annotated with emotional labels using attribute-based descriptors (activation, dominance and valence) and categorical labels (anger, happiness, sadness, disgust, surprised, fear, contempt, neutral and other).</sub>                                   | <sub>Audio</sub>              | <sub>--</sub>           | <sub>--</sub>                                                     | <sub>[The MSP-Conversation Corpus](http://www.interspeech2020.org/index.php?m=content&c=index&a=show&catid=290&id=684)</sub>                                                                                                                                                                                                                              | <sub>Restricted</sub>     | <sub>Academic License & Commercial License</sub>                                                                                          |
| <sub>[emotiontts open db](https://github.com/emotiontts/emotiontts_open_db)</sub>                                                                 | <sub>2020</sub> | <sub>Recordings and their associated transcriptions by a diverse group of speakers.</sub>                                                                                 | <sub>4 emotions: general, joy, anger, and sadness.</sub>                                                                                                                                                                                                                     | <sub>Audio, Text</sub>        | <sub>--</sub>           | <sub>Korean</sub>                                                 | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Partially open</sub> | <sub>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)</sub>                                                          |
| <sub>[URDU-Dataset](https://github.com/siddiquelatif/urdu-dataset)</sub>                                                                          | <sub>2020</sub> | <sub>400 utterances by 38 speakers (27 male and 11 female).</sub>                                                                                                         | <sub>4 emotions: angry, happy, neutral, and sad.</sub>                                                                                                                                                                                                                       | <sub>Audio</sub>              | <sub>0.072 GB</sub>     | <sub>Urdu</sub>                                                   | <sub>[Cross Lingual Speech Emotion Recognition: Urdu vs. Western Languages](https://arxiv.org/pdf/1812.10411.pdf)</sub>                                                                                                                                                                                                                                   | <sub>Open</sub>           | <sub>--</sub>                                                                                                                             |
| <sub>[BAVED](https://www.kaggle.com/a13x10/basic-arabic-vocal-emotions-dataset)</sub>                                                             | <sub>2020</sub> | <sub>1935 recording by 61 speakers (45 male and 16 female).</sub>                                                                                                         | <sub>3 levels of emotion.</sub>                                                                                                                                                                                                                                              | <sub>Audio</sub>              | <sub>0.195 GB</sub>     | <sub>Arabic</sub>                                                 | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>--</sub>                                                                                                                             |
| <sub>[VIVAE](https://zenodo.org/record/4066235)</sub>                                                                                             | <sub>2020</sub> | <sub>non-speech, 1085 audio file by 12 speakers.</sub>                                                                                                                    | <sub>non-speech 6 emotions: achievement, anger, fear, pain, pleasure, and surprise with 3 emotional intensities (low, moderate, strong, peak).</sub>                                                                                                                         | <sub>Audio</sub>              | <sub>--</sub>           | <sub>--</sub>                                                     | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Restricted</sub>     | <sub>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)</sub>                                                          |
| <sub>[SEWA](https://db.sewaproject.eu/)</sub>                                                                                                     | <sub>2019</sub> | <sub>more than 2000 minutes of audio-visual data of 398 people (201 male and 197 female) coming from 6 cultures.</sub>                                                    | <sub>emotions are characterized using valence and arousal.</sub>                                                                                                                                                                                                             | <sub>Audio, Video</sub>       | <sub>--</sub>           | <sub>Chinese, English, German, Greek, Hungarian and Serbian</sub> | <sub>[SEWA DB: A Rich Database for Audio-Visual Emotion and Sentiment Research in the Wild](https://arxiv.org/pdf/1901.02839.pdf)</sub>                                                                                                                                                                                                                   | <sub>Restricted</sub>     | <sub>[SEWA EULA](https://db.sewaproject.eu/media/doc/eula.pdf)</sub>                                                                      |
| <sub>[MELD](https://affective-meld.github.io/)</sub>                                                                                              | <sub>2019</sub> | <sub>1400 dialogues and 14000 utterances from Friends TV series  by multiple speakers.</sub>                                                                              | <sub>7 emotions: Anger, disgust, sadness, joy, neutral, surprise and fear.  MELD also has sentiment (positive, negative and neutral) annotation  for each utterance.</sub>                                                                                                   | <sub>Audio, Video, Text</sub> | <sub>10.1 GB</sub>      | <sub>English</sub>                                                | <sub>[MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations](https://arxiv.org/pdf/1810.02508.pdf)</sub>                                                                                                                                                                                                                        | <sub>Open</sub>           | <sub>[MELD: GPL-3.0 License](https://github.com/declare-lab/MELD/blob/master/LICENSE)</sub>                                               |
| <sub>[ShEMO](https://github.com/mansourehk/ShEMO)</sub>                                                                                           | <sub>2019</sub> | <sub>3000 semi-natural utterances, equivalent to 3 hours and 25 minutes of speech data from online radio plays by 87 native-Persian speakers.</sub>                       | <sub>6 emotions: anger, fear, happiness, sadness, neutral and surprise.</sub>                                                                                                                                                                                                | <sub>Audio</sub>              | <sub>0.101 GB</sub>     | <sub>Persian</sub>                                                | <sub>[ShEMO: a large-scale validated database for Persian speech emotion detection](https://link.springer.com/article/10.1007/s10579-018-9427-x)</sub>                                                                                                                                                                                                    | <sub>Open</sub>           | <sub>--</sub>                                                                                                                             |
| <sub>[DEMoS](https://zenodo.org/record/2544829)</sub>                                                                                             | <sub>2019</sub> | <sub>9365 emotional and 332 neutral samples produced by 68 native speakers (23 females, 45 males).</sub>                                                                  | <sub>7/6 emotions: anger, sadness, happiness, fear, surprise, disgust, and the secondary emotion guilt.</sub>                                                                                                                                                                | <sub>Audio</sub>              | <sub>--</sub>           | <sub>Italian</sub>                                                | <sub>[DEMoS: An Italian emotional speech corpus. Elicitation methods, machine learning, and perception](https://link.springer.com/epdf/10.1007/s10579-019-09450-y?author_access_token=5pf0w_D4k9z28TM6n4PbVPe4RwlQNchNByi7wbcMAY5hiA-aXzXNbZYfsMDDq2CdHD-w5ArAxIwlsk2nC_26pSyEAcu1xlKJ1c9m3JZj2ZlFmlVoCZUTcG3Hq2_2ozMLo3Hq3Y0CHzLdTxihQwch5Q%3D%3D)</sub> | <sub>Restricted</sub>     | <sub>EULA: End User License Agreement</sub>                                                                                               |
| <sub>[AESDD](http://m3c.web.auth.gr/research/aesdd-speech-emotion-recognition/)</sub>                                                             | <sub>2018</sub> | <sub>around 500 utterances by a diverse group of actors (over 5 actors) siumlating various emotions.</sub>                                                                | <sub>5 emotions: anger, disgust, fear, happiness, and sadness.</sub>                                                                                                                                                                                                         | <sub>Audio</sub>              | <sub>0.392 GB</sub>     | <sub>Greek</sub>                                                  | <sub>[Speech Emotion Recognition for Performance Interaction](https://www.researchgate.net/publication/326005164_Speech_Emotion_Recognition_for_Performance_Interaction)</sub>                                                                                                                                                                            | <sub>Open</sub>           | <sub>--</sub>                                                                                                                             |
| <sub>[Emov-DB](https://mega.nz/#F!KBp32apT!gLIgyWf9iQ-yqnWFUFuUHg!mYwUnI4K)</sub>                                                                 | <sub>2018</sub> | <sub>Recordings for 4 speakers- 2 males and 2 females.</sub>                                                                                                              | <sub>The emotional styles are neutral, sleepiness, anger, disgust and amused.</sub>                                                                                                                                                                                          | <sub>Audio</sub>              | <sub>5.88 GB</sub>      | <sub>English</sub>                                                | <sub>[The emotional voices database: Towards controlling the emotion dimension in voice generation systems](https://arxiv.org/pdf/1806.09514.pdf)</sub>                                                                                                                                                                                                   | <sub>Open</sub>           | <sub>--</sub>                                                                                                                             |
| <sub>[RAVDESS](https://zenodo.org/record/1188976#.XrC7a5NKjOR)</sub>                                                                              | <sub>2018</sub> | <sub>7356 recordings by 24 actors.</sub>                                                                                                                                  | <sub>7 emotions: calm, happy, sad, angry, fearful, surprise, and disgust</sub>                                                                                                                                                                                               | <sub>Audio, Video</sub>       | <sub>24.8 GB</sub>      | <sub>English</sub>                                                | <sub>[The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0196391)</sub>                                                                                                     | <sub>Open</sub>           | <sub>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)</sub>                                                          |
| <sub>[JL corpus](https://www.kaggle.com/tli725/jl-corpus)</sub>                                                                                   | <sub>2018</sub> | <sub>2400 recording of 240 sentences by 4 actors (2 males and 2 females).</sub>                                                                                           | <sub>5 primary emotions: angry, sad, neutral, happy, excited. 5 secondary emotions: anxious, apologetic, pensive, worried, enthusiastic.</sub>                                                                                                                               | <sub>Audio</sub>              | <sub>--</sub>           | <sub>English</sub>                                                | <sub>[An Open Source Emotional Speech Corpus for Human Robot Interaction Applications](https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1349.pdf)</sub>                                                                                                                                                                                          | <sub>Open</sub>           | <sub>[CC0 1.0](https://creativecommons.org/publicdomain/zero/1.0/)</sub>                                                                  |
| <sub>[CaFE](https://zenodo.org/record/1478765)</sub>                                                                                              | <sub>2018</sub> | <sub>6 different sentences by 12 speakers (6 fmelaes + 6 males).</sub>                                                                                                    | <sub>7 emotions: happy, sad, angry, fearful, surprise, disgust and neutral. Each emotion is acted in 2 different intensities.</sub>                                                                                                                                          | <sub>Audio</sub>              | <sub>2 GB</sub>         | <sub>French (Canadian)</sub>                                      | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)</sub>                                                          |
| <sub>[EmoFilm](https://zenodo.org/record/1326428)</sub>                                                                                           | <sub>2018</sub> | <sub>1115 audio instances sentences extracted from various films.</sub>                                                                                                   | <sub>5 emotions: anger, contempt, happiness, fear, and sadness.</sub>                                                                                                                                                                                                        | <sub>Audio</sub>              | <sub>--</sub>           | <sub>English, Italian & Spanish</sub>                             | <sub>[Categorical vs Dimensional Perception of Italian Emotional Speech](https://pdfs.semanticscholar.org/e70e/fcf7f5b4c366a7b7e2c16267d7f7691a5391.pdf)</sub>                                                                                                                                                                                            | <sub>Restricted</sub>     | <sub>EULA: End User License Agreement</sub>                                                                                               |
| <sub>[ANAD](https://www.kaggle.com/suso172/arabic-natural-audio-dataset)</sub>                                                                    | <sub>2018</sub> | <sub>1384 recording by multiple speakers.</sub>                                                                                                                           | <sub>3 emotions: angry, happy, surprised.</sub>                                                                                                                                                                                                                              | <sub>Audio</sub>              | <sub>2 GB</sub>         | <sub>Arabic</sub>                                                 | <sub>[Arabic Natural Audio Dataset](https://data.mendeley.com/datasets/xm232yxf7t/1)</sub>                                                                                                                                                                                                                                                                | <sub>Open</sub>           | <sub>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)</sub>                                                          |
| <sub>[EmoSynth](https://zenodo.org/record/3727593)</sub>                                                                                          | <sub>2018</sub> | <sub>144 audio file labelled by 40 listeners.</sub>                                                                                                                       | <sub>Emotion (no speech) defined in regard of valence and arousal.</sub>                                                                                                                                                                                                     | <sub>Audio</sub>              | <sub>0.1034 GB</sub>    | <sub>--</sub>                                                     | <sub>[The Perceived Emotion of Isolated Synthetic Audio: The EmoSynth Dataset and Results](https://dl.acm.org/doi/10.1145/3243274.3243277)</sub>                                                                                                                                                                                                          | <sub>Open</sub>           | <sub>[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)</sub>                                                                      |
| <sub>[CMU-MOSEI](https://www.amir-zadeh.com/datasets)</sub>                                                                                       | <sub>2018</sub> | <sub>65 hours of annotated video from more than 1000 speakers and 250 topics.</sub>                                                                                       | <sub>6 Emotion (happiness, sadness, anger,fear, disgust, surprise) + Likert scale.</sub>                                                                                                                                                                                     | <sub>Audio, Video</sub>       | <sub>--</sub>           | <sub>English</sub>                                                | <sub>[Multi-attention Recurrent Network for Human Communication Comprehension](https://arxiv.org/pdf/1802.00923.pdf)</sub>                                                                                                                                                                                                                                | <sub>Open</sub>           | <sub>[CMU-MOSEI License](https://github.com/A2Zadeh/CMU-MultimodalSDK/blob/master/LICENSE.txt)</sub>                                      |
| <sub>[VERBO](https://sites.google.com/view/verbodatabase/home)</sub>                                                                              | <sub>2018</sub> | <sub>14 different phrases by 12 speakers (6 female + 6 male) for a total of 1167 recordings.</sub>                                                                        | <sub>7 emotions: Happiness, Disgust, Fear, Neutral, Anger, Surprise, Sadness</sub>                                                                                                                                                                                           | <sub>Audio</sub>              | <sub>--</sub>           | <sub>Portuguese</sub>                                             | <sub>[VERBO: Voice Emotion Recognition dataBase in Portuguese Language](https://thescipub.com/pdf/jcssp.2018.1420.1430.pdf)</sub>                                                                                                                                                                                                                         | <sub>Restricted</sub>     | <sub>Available for research purposes only</sub>                                                                                           |
| <sub>[CMU-MOSI](https://www.amir-zadeh.com/datasets)</sub>                                                                                        | <sub>2017</sub> | <sub>2199 opinion utterances with annotated sentiment.</sub>                                                                                                              | <sub>Sentiment annotated between very negative to very positive in seven Likert steps.</sub>                                                                                                                                                                                 | <sub>Audio, Video</sub>       | <sub>--</sub>           | <sub>English</sub>                                                | <sub>[Multi-attention Recurrent Network for Human Communication Comprehension](https://arxiv.org/pdf/1802.00923.pdf)</sub>                                                                                                                                                                                                                                | <sub>Open</sub>           | <sub>[CMU-MOSI License](https://github.com/A2Zadeh/CMU-MultimodalSDK/blob/master/LICENSE.txt)</sub>                                       |
| <sub>[MSP-IMPROV](https://ecs.utdallas.edu/research/researchlabs/msp-lab/MSP-Improv.html)</sub>                                                   | <sub>2017</sub> | <sub>20 sentences by 12 actors.</sub>                                                                                                                                     | <sub>4 emotions: angry, sad, happy, neutral, other, without agreement</sub>                                                                                                                                                                                                  | <sub>Audio, Video</sub>       | <sub>--</sub>           | <sub>English</sub>                                                | <sub>[MSP-IMPROV: An Acted Corpus of Dyadic Interactions to Study Emotion Perception](https://ecs.utdallas.edu/research/researchlabs/msp-lab/publications/Busso_2017.pdf)</sub>                                                                                                                                                                           | <sub>Restricted</sub>     | <sub>Academic License & Commercial License</sub>                                                                                          |
| <sub>[CREMA-D](https://github.com/CheyneyComputerScience/CREMA-D)</sub>                                                                           | <sub>2017</sub> | <sub>7442 clip of 12 sentences spoken by 91 actors (48 males and 43 females).</sub>                                                                                       | <sub>6 emotions: angry, disgusted, fearful, happy, neutral, and sad</sub>                                                                                                                                                                                                    | <sub>Audio, Video</sub>       | <sub>--</sub>           | <sub>English</sub>                                                | <sub>[CREMA-D: Crowd-sourced Emotional Multimodal Actors Dataset](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4313618/)</sub>                                                                                                                                                                                                                            | <sub>Open</sub>           | <sub>[Open Database License & Database Content License](https://github.com/CheyneyComputerScience/CREMA-D/blob/master/LICENSE.txt)</sub>  |
| <sub>[Example emotion videos used in investigation of emotion perception in schizophrenia](https://espace.library.uq.edu.au/view/UQ:446541)</sub> | <sub>2017</sub> | <sub>6 videos:Two example videos from each emotion category (angry, happy and neutral) by one female speaker.</sub>                                                       | <sub>3 emotions: angry, happy and neutral.</sub>                                                                                                                                                                                                                             | <sub>Audio, Video</sub>       | <sub>0.063 GB</sub>     | <sub>English</sub>                                                | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>[Permitted Non-commercial Re-use with Acknowledgment](https://guides.library.uq.edu.au/deposit_your_data/terms_and_conditions)</sub> |
| <sub>[EMOVO](http://voice.fub.it/activities/corpora/emovo/index.html)</sub>                                                                       | <sub>2014</sub> | <sub>6 actors  who  played  14  sentences.</sub>                                                                                                                          | <sub>6 emotions: disgust, fear, anger, joy, surprise, sadness.</sub>                                                                                                                                                                                                         | <sub>Audio</sub>              | <sub>0.355 GB</sub>     | <sub>Italian</sub>                                                | <sub>[EMOVO Corpus: an Italian Emotional Speech Database](https://core.ac.uk/download/pdf/53857389.pdf)</sub>                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>--</sub>                                                                                                                             |
| <sub>[RECOLA](https://diuf.unifr.ch/main/diva/recola/download.html)</sub>                                                                         | <sub>2013</sub> | <sub>3.8 hours of recordings by 46 participants.</sub>                                                                                                                    | <sub>negative and positive sentiment (valence and arousal).</sub>                                                                                                                                                                                                            | <sub>Audio, Video</sub>       | <sub>--</sub>           | <sub>--</sub>                                                     | <sub>[Introducing the RECOLA Multimodal Corpus of Remote Collaborative and Affective Interactions](https://drive.google.com/file/d/0B2V_I9XKBODhNENKUnZWNFdVXzQ/view)</sub>                                                                                                                                                                               | <sub>Restricted</sub>     | <sub>Academic License & Commercial License</sub>                                                                                          |
| <sub>[GEMEP corpus](https://www.unige.ch/cisa/gemep)</sub>                                                                                        | <sub>2012</sub> | <sub>Videos10 actors portraying 10 states.</sub>                                                                                                                          | <sub>12 emotions: amusement, anxiety, cold anger (irritation), despair, hot anger (rage),  fear (panic), interest, joy (elation), pleasure(sensory), pride, relief, and sadness. Plus, 5 additional emotions: admiration, contempt, disgust, surprise, and tenderness.</sub> | <sub>Audio, Video</sub>       | <sub>--</sub>           | <sub>French</sub>                                                 | <sub>[Introducing the Geneva Multimodal Expression Corpus for Experimental Research on Emotion Perception](https://www.researchgate.net/publication/51796867_Introducing_the_Geneva_Multimodal_Expression_Corpus_for_Experimental_Research_on_Emotion_Perception)</sub>                                                                                   | <sub>Restricted</sub>     | <sub>--</sub>                                                                                                                             |
| <sub>[OGVC](https://sites.google.com/site/ogcorpus/home/en)</sub>                                                                                 | <sub>2012</sub> | <sub>9114 spontaneous utterances and 2656 acted utterances by 4 professional actors (two male and two female).</sub>                                                      | <sub>9 emotional states: fear, surprise, sadness, disgust, anger, anticipation, joy, acceptance and the neutral state.</sub>                                                                                                                                                 | <sub>Audio</sub>              | <sub>--</sub>           | <sub>Japanese</sub>                                               | <sub>[Naturalistic emotional speech collectionparadigm with online game and its psychological and acoustical assessment](https://www.jstage.jst.go.jp/article/ast/33/6/33_E1175/_pdf)</sub>                                                                                                                                                               | <sub>Restricted</sub>     | <sub>--</sub>                                                                                                                             |
| <sub>[LEGO corpus](https://www.ultes.eu/ressources/lego-spoken-dialogue-corpus/)</sub>                                                            | <sub>2012</sub> | <sub>347 dialogs with 9,083 system-user exchanges.</sub>                                                                                                                  | <sub>Emotions classified as garbage, non-angry, slightly angry and very angry.</sub>                                                                                                                                                                                         | <sub>Audio</sub>              | <sub>1.1 GB</sub>       | <sub>--</sub>                                                     | <sub>[A Parameterized and Annotated Spoken Dialog Corpus of the CMU Let’s Go Bus Information System](http://www.lrec-conf.org/proceedings/lrec2012/pdf/333_Paper.pdf)</sub>                                                                                                                                                                               | <sub>Open</sub>           | <sub>License available with the data. Free of charges for research purposes only.</sub>                                                   |
| <sub>[SEMAINE](https://semaine-db.eu/)</sub>                                                                                                      | <sub>2012</sub> | <sub>95 dyadic conversations from 21 subjects. Each subject converses with another playing one of four characters with emotions.</sub>                                    | <sub>5 FeelTrace annotations: activation, valence, dominance, power, intensity</sub>                                                                                                                                                                                         | <sub>Audio, Video, Text</sub> | <sub>104 GB</sub>       | <sub>English</sub>                                                | <sub>[The SEMAINE Database: Annotated Multimodal Records of Emotionally Colored Conversations between a Person and a Limited Agent](https://ieeexplore.ieee.org/document/5959155)</sub>                                                                                                                                                                   | <sub>Restricted</sub>     | <sub>Academic EULA</sub>                                                                                                                  |
| <sub>[SAVEE](http://kahlan.eps.surrey.ac.uk/savee/Database.html)</sub>                                                                            | <sub>2011</sub> | <sub>480 British English utterances by 4 males actors.</sub>                                                                                                              | <sub>7 emotions: anger, disgust, fear, happiness, sadness, surprise and neutral.</sub>                                                                                                                                                                                       | <sub>Audio, Video</sub>       | <sub>--</sub>           | <sub>English (British)</sub>                                      | <sub>[Multimodal Emotion Recognition](http://personal.ee.surrey.ac.uk/Personal/P.Jackson/pub/ma10/HaqJackson_MachineAudition10_approved.pdf)</sub>                                                                                                                                                                                                        | <sub>Restricted</sub>     | <sub>Free of charges for research purposes only.</sub>                                                                                    |
| <sub>[TESS](https://tspace.library.utoronto.ca/handle/1807/24487)</sub>                                                                           | <sub>2010</sub> | <sub>2800 recording by 2 actresses.</sub>                                                                                                                                 | <sub>7 emotions: anger, disgust, fear, happiness, pleasant surprise, sadness, and neutral.</sub>                                                                                                                                                                             | <sub>Audio</sub>              | <sub>--</sub>           | <sub>English</sub>                                                | <sub>[BEHAVIOURAL FINDINGS FROM THE TORONTO EMOTIONAL SPEECH SET](https://www.semanticscholar.org/paper/BEHAVIOURAL-FINDINGS-FROM-THE-TORONTO-EMOTIONAL-SET-Dupuis-Pichora-Fuller/d7f746b3aee801a353b6929a65d9a34a68e71c6f/figure/2)</sub>                                                                                                                | <sub>Open</sub>           | <sub>[CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)</sub>                                                          |
| <sub>[EEKK](https://metashare.ut.ee/repository/download/4d42d7a8463411e2a6e4005056b40024a19021a316b54b7fb707757d43d1a889/)</sub>                  | <sub>2007</sub> | <sub>26 text passage read by 10 speakers.</sub>                                                                                                                           | <sub>4 main emotions: joy, sadness, anger and neutral.</sub>                                                                                                                                                                                                                 | <sub>--</sub>                 | <sub>0.352 GB</sub>     | <sub>Estonian</sub>                                               | <sub>[Estonian Emotional Speech Corpus](https://www.researchgate.net/publication/261724574_Estonian_Emotional_Speech_Corpus_Release_1)</sub>                                                                                                                                                                                                              | <sub>Open</sub>           | <sub>[CC-BY license](https://metashare.ut.ee/repository/download/4d42d7a8463411e2a6e4005056b40024a19021a316b54b7fb707757d43d1a889/)</sub> |
| <sub>[IEMOCAP](https://sail.usc.edu/iemocap/iemocap_release.htm)</sub>                                                                            | <sub>2007</sub> | <sub>12 hours of audiovisual data by 10 actors.</sub>                                                                                                                     | <sub>5 emotions: happiness, anger, sadness, frustration and neutral.</sub>                                                                                                                                                                                                   | <sub>--</sub>                 | <sub>--</sub>           | <sub>English</sub>                                                | <sub>[IEMOCAP: Interactive emotional dyadic motion capture database](https://sail.usc.edu/iemocap/Busso_2008_iemocap.pdf)</sub>                                                                                                                                                                                                                           | <sub>Restricted</sub>     | <sub>[IEMOCAP license](https://sail.usc.edu/iemocap/Data_Release_Form_IEMOCAP.pdf)</sub>                                                  |
| <sub>[Keio-ESD](http://research.nii.ac.jp/src/en/Keio-ESD.html)</sub>                                                                             | <sub>2006</sub> | <sub>A set of human speech with vocal emotion spoken by a Japanese male speaker.</sub>                                                                                    | <sub>47 emotions including angry, joyful, disgusting, downgrading, funny,  worried, gentle, relief, indignation, shameful, etc.</sub>                                                                                                                                        | <sub>Audio</sub>              | <sub>--</sub>           | <sub>Japanese</sub>                                               | <sub>[EMOTIONAL SPEECH SYNTHESIS USING SUBSPACE CONSTRAINTS IN PROSODY](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.420.8899&rep=rep1&type=pdf)</sub>                                                                                                                                                                                        | <sub>Restricted</sub>     | <sub>Available for research purposes only.</sub>                                                                                          |
| <sub>[EMO-DB](http://emodb.bilderbar.info/index-1280.html)</sub>                                                                                  | <sub>2005</sub> | <sub>800 recording spoken by 10 actors (5 males and 5 females).</sub>                                                                                                     | <sub>7 emotions: anger, neutral, fear, boredom, happiness, sadness, disgust.</sub>                                                                                                                                                                                           | <sub>Audio</sub>              | <sub>--</sub>           | <sub>German</sub>                                                 | <sub>[A Database of German Emotional Speech](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.130.8506&rep=rep1&type=pdf)</sub>                                                                                                                                                                                                                   | <sub>Open</sub>           | <sub>--</sub>                                                                                                                             |
| <sub>[eNTERFACE05](http://www.enterface.net/enterface05/docs/results/databases/project2_database.zip)</sub>                                       | <sub>2005</sub> | <sub>Videos by 42 subjects, coming from 14 different nationalities.</sub>                                                                                                 | <sub>6 emotions: anger, fear, surprise, happiness, sadness and disgust.</sub>                                                                                                                                                                                                | <sub>Audio, Video</sub>       | <sub>0.8 GB</sub>       | <sub>German</sub>                                                 | <sub>--</sub>                                                                                                                                                                                                                                                                                                                                             | <sub>Open</sub>           | <sub>Free of charges for research purposes only.</sub>                                                                                    |
| <sub>[DES](http://kom.aau.dk/~tb/speech/Emotions/)</sub>                                                                                          | <sub>2002</sub> | <sub>4 speakers (2 males and 2 females).</sub>                                                                                                                            | <sub>5 emotions: neutral,  surprise,  happiness,  sadness  and  anger</sub>                                                                                                                                                                                                  | <sub>--</sub>                 | <sub>--</sub>           | <sub>Danish</sub>                                                 | <sub>[Documentation of the Danish Emotional Speech Database](http://kom.aau.dk/~tb/speech/Emotions/des.pdf)</sub>                                                                                                                                                                                                                                         | <sub>--</sub>             | <sub>--</sub>                                                                                                                             |## References

- Swain, Monorama & Routray, Aurobinda & Kabisatpathy, Prithviraj, Databases, features and classifiers for speech emotion recognition: a review, International Journal of Speech Technology, [paper](https://www.researchgate.net/publication/322602563_Databases_features_and_classifiers_for_speech_emotion_recognition_a_review#pf19)
- Dimitrios Ververidis and Constantine Kotropoulos, A State of the Art Review on Emotional Speech Databases, Artificial Intelligence & Information Analysis Laboratory, Department of Informatics Aristotle, University of Thessaloniki, [paper](http://poseidon.csd.auth.gr/papers/PUBLISHED/CONFERENCE/pdf/Ververidis2003b.pdf)
- A. Pramod Reddy and V. Vijayarajan, Extraction of Emotions from Speech-A Survey, VIT University, International Journal of Applied Engineering Research, [paper](https://www.ripublication.com/ijaer17/ijaerv12n16_46.pdf)
- Emotional Speech Databases, [document](https://link.springer.com/content/pdf/bbm%3A978-90-481-3129-7%2F1.pdf)
- Expressive Synthetic Speech, [website](http://emosamples.syntheticspeech.de/)
- Towards a standard set of acoustic features for the processing of emotion in speech, Technical university Munich, [document](https://asa.scitation.org/doi/pdf/10.1121/1.4739483)


## Contribution

- All contributions are welcome! If you know a dataset that belongs here (see [criteria](https://github.com/SuperKogito/SER-datasets/blob/master/CONTRIBUTING.md#criteria)) but is not listed, please feel free to add it. For more information on Contributing, please refer to [CONTRIBUTING.md](https://github.com/SuperKogito/SER-datasets/blob/master/CONTRIBUTING.md).

-  If you notice a typo or a mistake, please [report this as an issue](https://github.com/SuperKogito/SER-datasets/issues/new) and help us improve the quality of this list.


## Disclaimer
- The mainter and the contributors try their best to keep this list up-to-date, and to only include working links (using automated verification with the help of the [urlchecker-action](https://github.com/marketplace/actions/urlchecker-action)). However, we cannot guarantee that all listed links are up-to-date. Read more in [DISCLAIMER.md](https://github.com/SuperKogito/SER-datasets/blob/master/DISCLAIMER.md).
